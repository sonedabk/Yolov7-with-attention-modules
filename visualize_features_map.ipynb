{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["YOLOR ðŸš€ v0.1-149-gdfb2f22 torch 2.0.1+cu117 CPU\n","\n"]},{"name":"stdout","output_type":"stream","text":["Trace model False\n","Fusing layers... \n","IDetect.fuse\n"]},{"name":"stderr","output_type":"stream","text":["Model Summary: 343 layers, 6175567 parameters, 0 gradients, 13.3 GFLOPS\n"]},{"name":"stdout","output_type":"stream","text":["CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=128, out_features=8, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=8, out_features=128, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=256, out_features=16, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=16, out_features=256, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=128, out_features=8, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=8, out_features=128, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=128, out_features=8, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=8, out_features=128, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=128, out_features=8, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=8, out_features=128, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=256, out_features=16, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=16, out_features=256, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=256, out_features=16, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=16, out_features=256, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=256, out_features=16, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=16, out_features=256, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=512, out_features=32, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=32, out_features=512, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=512, out_features=32, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=32, out_features=512, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","CBAM(\n","  (channel_attention): ChannelAttentionModule(\n","    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","    (max_pool): AdaptiveMaxPool2d(output_size=1)\n","    (shared_MLP): Sequential(\n","      (0): Linear(in_features=512, out_features=32, bias=True)\n","      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (2): Linear(in_features=32, out_features=512, bias=True)\n","    )\n","    (act): Sigmoid()\n","  )\n","  (spatial_attention): SpatialAttentionModule(\n","    (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (act): Sigmoid()\n","  )\n",")\n","Done. (0.015s)\n"]}],"source":["import argparse\n","import time\n","from pathlib import Path\n","\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n","    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n","from models.common import CBAM\n","\n","\n","def detect(save_img=False):\n","    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n","    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n","    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n","        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n","    \n","    print(\"Trace model\", trace)\n","\n","    # Directories\n","    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n","    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Initialize\n","    set_logging()\n","    device = select_device(opt.device)\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","    stride = int(model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","\n","    if trace:\n","        model = TracedModel(model, device, opt.img_size)\n","\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Second-stage classifier\n","    classify = False\n","    if classify:\n","        modelc = load_classifier(name='resnet101', n=2)  # initialize\n","        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    if webcam:\n","        view_img = check_imshow()\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n","\n","    # Run inference\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    old_img_w = old_img_h = imgsz\n","    old_img_b = 1\n","\n","    t0 = time.time()\n","    for path, img, im0s, vid_cap in dataset:\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Warmup\n","        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n","            old_img_b = img.shape[0]\n","            old_img_h = img.shape[2]\n","            old_img_w = img.shape[3]\n","            for i in range(3):\n","                model(img, augment=opt.augment)[0]\n","\n","        \n","        for layer in model.modules():\n","            if isinstance(layer, CBAM):\n","                print(layer)\n","        # Inference\n","        # t1 = time_synchronized()\n","        # with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","        #     pred = model(img, augment=opt.augment)[0]\n","        # t2 = time_synchronized()\n","\n","        \n","\n","    print(f'Done. ({time.time() - t0:.3f}s)')\n","\n","\n","if __name__ == '__main__':\n","\n","    \n","    class Params:\n","        weights = \"./runs/train/exp17/weights/best.pt\"\n","        source = './visualize_imgs/0000084_00000_d_0000001.jpg'\n","        img_size = 640\n","        conf_thres = 0.25\n","        iou_thres = 0.45\n","        device = 'cpu'\n","        view_img = None\n","        save_txt = None\n","        save_conf = None\n","        nosave = None\n","        classes = None\n","        agnostic_nms = None\n","        augment = None\n","        update = None\n","        project = \"\"\n","        name = \"\"\n","        exist_ok = \"\"\n","        no_trace = True\n","        \n","\n","\n","\n","    opt = Params()\n","\n","\n","\n","    detect()\n"]}],"metadata":{"kernelspec":{"display_name":"yolov7","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
